{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-ARC Neural Cellular Automata [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/46_1d_arc_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.10 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda12]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core.ca import CA\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import ResidualUpdate\n",
    "from cax.utils import clip_and_uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_spatial_dims = 1\n",
    "channel_size = 64\n",
    "num_kernels = 2\n",
    "hidden_layer_sizes = (256,)\n",
    "cell_dropout_rate = 0.0\n",
    "\n",
    "num_embeddings = 10  # 10 colors in total\n",
    "features = 3  # embed in rgb\n",
    "\n",
    "batch_size = 16\n",
    "num_steps = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "ds_size = 96\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalil-research/1D-ARC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"./1D-ARC/dataset\"\n",
    "\n",
    "\n",
    "def process(input, output):\n",
    "\t\"\"\"Process input and output from dataset.\"\"\"\n",
    "\tinput = jnp.squeeze(jnp.array(input, dtype=jnp.int32))\n",
    "\toutput = jnp.squeeze(jnp.array(output, dtype=jnp.int32))\n",
    "\tassert input.shape == output.shape\n",
    "\n",
    "\tpad_size = ds_size - input.size\n",
    "\tpad_left, pad_right = pad_size // 2, pad_size - pad_size // 2\n",
    "\n",
    "\tinput_padded = jnp.pad(input, (pad_left, pad_right))\n",
    "\toutput_padded = jnp.pad(output, (pad_left, pad_right))\n",
    "\n",
    "\treturn jnp.stack([input_padded, output_padded])\n",
    "\n",
    "\n",
    "ds = []\n",
    "tasks = []\n",
    "for task_idx, task_name in enumerate(os.listdir(ds_path)):\n",
    "\ttask_path = os.path.join(ds_path, task_name)\n",
    "\tfor task_file in os.listdir(task_path):\n",
    "\t\twith open(os.path.join(task_path, task_file)) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tinput_output = jnp.array(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\tprocess(data[\"train\"][0][\"input\"], data[\"train\"][0][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][1][\"input\"], data[\"train\"][1][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][2][\"input\"], data[\"train\"][2][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"test\"][0][\"input\"], data[\"test\"][0][\"output\"]),\n",
    "\t\t\t\t],\n",
    "\t\t\t\tdtype=jnp.int32,\n",
    "\t\t\t)\n",
    "\t\t\ttasks.append(task_name)\n",
    "\t\t\tds.append(input_output)\n",
    "ds = jnp.stack(ds)\n",
    "\n",
    "unique_tasks = list(set(tasks))\n",
    "task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}\n",
    "tasks = jnp.array([task_to_idx[task] for task in tasks], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageColor\n",
    "\n",
    "# ARC-AGI colors\n",
    "colors = {\n",
    "\t0: \"#000000\",  # Black\n",
    "\t1: \"#0074D9\",  # Blue\n",
    "\t2: \"#FF4136\",  # Red\n",
    "\t3: \"#2ECC40\",  # Green\n",
    "\t4: \"#FFDC00\",  # Yellow\n",
    "\t5: \"#AAAAAA\",  # Grey\n",
    "\t6: \"#F012BE\",  # Fuchsia\n",
    "\t7: \"#FF851B\",  # Orange\n",
    "\t8: \"#7FDBFF\",  # Teal\n",
    "\t9: \"#870C25\",  # Brown\n",
    "}\n",
    "\n",
    "# Convert all ARC colors to RGB using PIL\n",
    "color_lookup = jnp.array([ImageColor.getrgb(hex) for hex in colors.values()]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "tasks = jax.random.permutation(subkey, tasks)\n",
    "ds = jax.random.permutation(subkey, ds)\n",
    "\n",
    "split = int(0.9 * ds.shape[0])\n",
    "\n",
    "train_ds = ds[:split]\n",
    "train_tasks = tasks[:split]\n",
    "\n",
    "test_ds = ds[split:]\n",
    "test_tasks = tasks[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_with_sample(ca, sample, key):\n",
    "\t\"\"\"Create state with sample.\"\"\"\n",
    "\t# Sample input and target\n",
    "\t(\n",
    "\t\t(input_embed_1, output_embed_1),\n",
    "\t\t(input_embed_2, output_embed_2),\n",
    "\t\t(input_embed_3, output_embed_3),\n",
    "\t\t(input_embed, _),\n",
    "\t) = ca.embed_input(sample)\n",
    "\n",
    "\t# Create context\n",
    "\tcontext_1 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_2 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_3 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_4 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_5 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_6 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext = jax.random.choice(\n",
    "\t\tkey, jnp.array([context_1, context_2, context_3, context_4, context_5, context_6])\n",
    "\t)\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\t# state = state.at[..., :3].set(input_embed)\n",
    "\tstate = state.at[..., 3 : 18 + 3].set(context)\n",
    "\tstate = state.at[..., -10:].set(jax.nn.one_hot(sample[-1, 0], num_classes=10))\n",
    "\treturn state, sample[-1, -1]\n",
    "\n",
    "\n",
    "def sample_state(ca, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_flip, key_perm, key_init = jax.random.split(key, 4)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, train_tasks)\n",
    "\tsample = jax.random.choice(key_sample, train_ds)\n",
    "\n",
    "\t# Flip sample half of the time\n",
    "\tflip = jax.random.bernoulli(key_flip, p=0.5)\n",
    "\tsample = jnp.where(flip < 0.5, sample, jnp.flip(sample, axis=-1))\n",
    "\n",
    "\t# Permute colors\n",
    "\tcolor_perm = jnp.concatenate(\n",
    "\t\t[jnp.array([0], dtype=jnp.int32), jax.random.permutation(key_perm, jnp.arange(9)) + 1]\n",
    "\t)\n",
    "\tsample = color_perm[sample]\n",
    "\n",
    "\treturn create_state_with_sample(ca, sample, key_init)\n",
    "\n",
    "\n",
    "def sample_state_test(ca, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_init = jax.random.split(key)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, test_tasks)\n",
    "\tsample = jax.random.choice(key_sample, test_ds)\n",
    "\n",
    "\treturn create_state_with_sample(ca, sample, key_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceive = ConvPerceive(\n",
    "\tchannel_size=channel_size,\n",
    "\tperception_size=num_kernels * channel_size,\n",
    "\trngs=rngs,\n",
    "\tkernel_size=(3,),\n",
    "\tfeature_group_count=channel_size,\n",
    ")\n",
    "update = ResidualUpdate(\n",
    "\tnum_spatial_dims=num_spatial_dims,\n",
    "\tchannel_size=channel_size,\n",
    "\tperception_size=num_kernels * channel_size,\n",
    "\thidden_layer_sizes=hidden_layer_sizes,\n",
    "\trngs=rngs,\n",
    "\tcell_dropout_rate=cell_dropout_rate,\n",
    "\tzeros_init=True,\n",
    ")\n",
    "embed_input = nnx.Embed(num_embeddings=num_embeddings, features=features, rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCNCA(CA):\n",
    "\t\"\"\"1D-ARC Neural Cellular Automata.\"\"\"\n",
    "\n",
    "\tdef __init__(self, perceive, update, embed_input):\n",
    "\t\t\"\"\"Initialize 1D-ARC NCA.\"\"\"\n",
    "\t\tsuper().__init__(perceive, update)\n",
    "\t\tself.embed_input = embed_input\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate(\n",
    "\t\t\t[identity_kernel(ndim=num_spatial_dims), grad_kernel(ndim=num_spatial_dims)], axis=-1\n",
    "\t\t)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel = nnx.Param(kernel)\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\t# Extract classification logits\n",
    "\t\tlogits = state[..., -10:]\n",
    "\n",
    "\t\t# Render to RGB\n",
    "\t\trgb = color_lookup[jnp.argmax(logits, axis=-1)]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = ARCNCA(perceive, update, embed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 49886\n"
     ]
    }
   ],
   "source": [
    "params = nnx.state(ca, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 100_000\n",
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=num_train_steps // 10\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "params = nnx.All(\n",
    "\tnnx.Param,\n",
    "\t# nnx.Not(nnx.PathContains(\"perceive\"))\n",
    ")\n",
    "optimizer = nnx.Optimizer(ca, optimizer, wrt=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(state, output):\n",
    "\t\"\"\"Cross-entropy.\"\"\"\n",
    "\treturn jnp.mean(optax.softmax_cross_entropy_with_integer_labels(state[..., -10:], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(ca, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tkeys = jax.random.split(key, batch_size)\n",
    "\tstate, output = jax.vmap(sample_state, in_axes=(None, 0))(ca, keys)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "\tstate, _ = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda ca, state: ca(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(ca, state)\n",
    "\n",
    "\tloss = ce(state, output)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(ca, optimizer, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tloss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, params))(ca, key)\n",
    "\toptimizer.update(grad)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ca, eval_ds):\n",
    "\t\"\"\"Compute accuracy.\"\"\"\n",
    "\teval_size = eval_ds.shape[0]\n",
    "\tstate, output = jax.vmap(create_state_with_sample, in_axes=(None, 0, None))(ca, eval_ds, key)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "\t_, state = nnx.split_rngs(splits=eval_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda ca, state: ca(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(ca, state)\n",
    "\n",
    "\t# Convert logits to symbols\n",
    "\tfinal_state_logits = state[:, -1, :, -10:]\n",
    "\tfinal_state = jnp.argmax(final_state_logits, axis=-1)\n",
    "\n",
    "\t# Successful if all symbols match in the prediction\n",
    "\treturn jnp.sum(jnp.all(final_state == output, axis=-1)) / eval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss = train_step(ca, optimizer, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\ttest_acc = accuracy(ca, test_ds)\n",
    "\t\ttrain_acc = accuracy(ca, train_ds)\n",
    "\t\tpbar.set_postfix(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"Average Loss\": f\"{avg_loss:.3e}\",\n",
    "\t\t\t\t\"Test Accuracy\": f\"{test_acc:.2%}\",\n",
    "\t\t\t\t\"Train Accuracy\": f\"{train_acc:.2%}\",\n",
    "\t\t\t}\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, num_examples)\n",
    "state_init, output = jax.vmap(sample_state_test, in_axes=(None, 0))(ca, keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "state_final, states = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda ca, state: ca(state, num_steps=num_steps),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(ca, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAA2UlEQVR4nO3YwQ0BQBBAUUQx+lOH/pTj4EKEJyJmJf/fN7P7MqfdbqY6nj85dTp8+x5o9+N5f1dAKCAUEAoIBYQCQgGhgFBAKCAUEAoIBYQCQksCnQ6///d51pJA19ZgWg9oAZTbRoHetBglW2yDHi2mF2oa6Pb9ry2GpPYjU++a3pHXTW/Qm80h/gnQXAGhgFBAKCAUEAoIBYQCQgGhgFBAKCAUEAoIBYQCQgGhgFBAKCAUEAoIBYQCQgGhgFBAKCAUEAoIBYQCQgGhgFBAKCAUEAoIBYQCQhcnfwxqaxzsbAAAAABJRU5ErkJggg==\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAAyUlEQVR4nO3Xyw3DIBQAQSfVuL/U4f5Sjiuw5gZ+0u6VA2jER3yON/f7Pw5d55olfNdMM7eAUEAoIBQQCggFhAJCAaGAUEAoIBQQej3Qql/7U68H2l1AKCAUEAoITQDa+pBNANpaQGgI0L5TNgRoX3OArnPLPpoDtKmAUEBoGtDya2ga0LHaaCDQ2gJCAaGAUEAoIBQQCggFhAJCAaGAUEAoIBQQCggFhAJCAaGAUEAoIBQQCggFhAJCAaGAUEAoIBQQCggFhAJCN9VTB3UehRndAAAAAElFTkSuQmCC\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAA4UlEQVR4nO3XsWkDQRRF0dU2ILYSR84FasrNLSh3MduBcWqBzMm0P7g3m4keJxnmsryxn9vny/v18f33eGz7dtzfssitZw+YXkAoIBQQCggFhAJCAaGAUEAoIDQC6L8/2oRGAE0uIBQQGgd0bPvZE54aBzStKUBjH7IpQMtUo0FAy0ijWUADCwgFhAJC44CuH19nT3hqHNC0AkIBoYBQQCggFBAKCAWEAkIBoYBQQCggFBAKCAWEAkIBoYBQQCggFBAKCAWEAkIBoYBQQCggFBAKCAWEAkIBoYBQQCggFBD6BWtoDsG7H7B2AAAAAElFTkSuQmCC\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAA6klEQVR4nO3XMUoDURRA0cEVmIVYWptlZguzBcEitZV1thDIDoKFTYiSg4L5v7iHqT4D87g8+Myy/L/z9vnruTxc1/X6tcMdZvm1h9EDzK5AUCAoEBQIZgk05xW2zBNoWgWCAkGBoEAwJtBp8/bj+dP7y50noTYIRgb6/kP/8bgfMskNbRAUCAoEYwK97o5DvvsHbRAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYHgE3+ZE1al+ovYAAAAAElFTkSuQmCC\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAAyUlEQVR4nO3aIQ4CMRBA0WXvhOfoeO5EsBsET86Q/Ofqmp+paNrbMeT9uF+X5/M1tZPfzukNbFcgKBAUCAoEBYICQYGgQFAg2BLo6+axx5ZAaxUIFgXaecoWBTpWNtoVaKECQYGgQFAgKBAUCAoEBYICQYGgQDAZaO17/FUTBGOB/mJ8jiaICgQFggJBgaBAUCAoEBQICgQFggJBgaBAUCAoEBQICgQFggJBgaBAUCAoEBQICgQFggLBcKD9XxiaICgQFAgKBAWCDyqADILvtvqIAAAAAElFTkSuQmCC\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Failure</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAA0UlEQVR4nO3asQ3CQBBFwcO9UJNrtOiFBugFEVhCEE3oDd5EF3697KS9rQGO4zgf+76vtd6vtd0vHfRju3rAdAWCAkGBoEBQICgQFAjGBXq/rl7wb1ygaQoEBYJZgb6/1jlmBRqoQFAgKBAUCAoEBYICQYGgQFAgKBAUCAoEBYICQYGgQFAgmBXoPKAaZVaggQoEBYICQYGgQFAgKBCMC/R4zrpfGBdomgJBgaBAUCAoEBQICgQFggJBgaBAUCAoEBQICgQFggJBgaBAUCAoEHwAidwMfRUuRekAAAAASUVORK5CYII=\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Failure</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAABNUlEQVR4nO3YO2rDQBhF4bFKN1qKqvTZgreR3uAihctAdpDNRG1QpQ14D2lSmhQ2RliGAyly7w/3VCMQzPAxem6aovPzUzdOl0FrrRuny2A5Xp5wO/z/OsmshQoQFCAoQFCAoABBRkDD+/bhWJsRkGcBgmoAfc9vqqlrAAkrACTcPq0EkLYAQQWA+uEgnL0AkLYAQQGCagAJb0M1gIQFCAoQFCAoQFCAoABBjkA+P6SbJ5BVAYJcgKwuq2UuQHe9nl7US7hmCuRTgKAAQQGCCgBpH3AFgLQFCAoQFCBIDGT7hXErOwgKEBQgKEBQgKAAQQGCAgR5ARm+N3oBrZOTuQPJCxAUIChAUIAgL6B5/6Newn1eQIYFCBID7fpP7QIwDdDx40sy7x/yusTkHxbrvIAMCxD0C+J3I2i4fJh1AAAAAElFTkSuQmCC\"/></div></div></div></td><td style=\"padding:1px;\"><div style=\"display:flex; align-items:left;\">\n",
       "      <div style=\"display:flex; flex-direction:column; align-items:center;\">\n",
       "      <div>Success</div><div><img width=\"196\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABBCAIAAAChCjb8AAAA6ElEQVR4nO3XQQrCQBQEUQ2eJcd0kWN6GHExe0tF0v2h3j6kKSYDuV5y7o/nD08d+/b3JW+c+rKJDAQMBAwEDAQMBAwEDAQMBAwEDAQMBPKBjn07+f/zK73LShgIhAM1f1xL0b7OWC2bVp3CC7trzVLVqGhKJwMBA4FJgSJ3U2mgnnu6ZUet3kAlh6hixCdSvQYEyh6lW/DdqOEryy8oNyNQ8CjNCBRkIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAg8AIp2w16Cu6S5AAAAABJRU5ErkJggg==\"/></div></div></div></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output_pred = jnp.argmax(state_final[..., -10:], axis=-1)\n",
    "success = jnp.all(output_pred == output, axis=-1)\n",
    "\n",
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = jax.vmap(ca.render)(states)\n",
    "\n",
    "# Add titles to each image to indicate success\n",
    "titles = [\"Success\" if s else \"Failure\" for s in success]\n",
    "mediapy.show_images(frames, width=196, height=128, titles=titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
