{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-ARC Neural Cellular Automata [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/46_1d_arc_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.10 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import ResidualUpdate\n",
    "from cax.types import Input, State\n",
    "from cax.utils import clip_and_uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_spatial_dims = 1\n",
    "channel_size = 64\n",
    "num_kernels = 2\n",
    "hidden_layer_sizes = (256,)\n",
    "cell_dropout_rate = 0.0\n",
    "\n",
    "num_embeddings = 10  # 10 colors in total\n",
    "features = 3  # embed in rgb\n",
    "\n",
    "num_steps = 64\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "ds_size = 96\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalil-research/1D-ARC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"./1D-ARC/dataset\"\n",
    "\n",
    "\n",
    "def process(input, output):\n",
    "\t\"\"\"Process input and output from dataset.\"\"\"\n",
    "\tinput = jnp.squeeze(jnp.array(input, dtype=jnp.int32))\n",
    "\toutput = jnp.squeeze(jnp.array(output, dtype=jnp.int32))\n",
    "\tassert input.shape == output.shape\n",
    "\n",
    "\tpad_size = ds_size - input.size\n",
    "\tpad_left, pad_right = pad_size // 2, pad_size - pad_size // 2\n",
    "\n",
    "\tinput_padded = jnp.pad(input, (pad_left, pad_right))\n",
    "\toutput_padded = jnp.pad(output, (pad_left, pad_right))\n",
    "\n",
    "\treturn jnp.stack([input_padded, output_padded])\n",
    "\n",
    "\n",
    "ds = []\n",
    "tasks = []\n",
    "for task_idx, task_name in enumerate(os.listdir(ds_path)):\n",
    "\ttask_path = os.path.join(ds_path, task_name)\n",
    "\tfor task_file in os.listdir(task_path):\n",
    "\t\twith open(os.path.join(task_path, task_file)) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tinput_output = jnp.array(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\tprocess(data[\"train\"][0][\"input\"], data[\"train\"][0][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][1][\"input\"], data[\"train\"][1][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][2][\"input\"], data[\"train\"][2][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"test\"][0][\"input\"], data[\"test\"][0][\"output\"]),\n",
    "\t\t\t\t],\n",
    "\t\t\t\tdtype=jnp.int32,\n",
    "\t\t\t)\n",
    "\t\t\ttasks.append(task_name)\n",
    "\t\t\tds.append(input_output)\n",
    "ds = jnp.stack(ds)\n",
    "\n",
    "unique_tasks = list(set(tasks))\n",
    "task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}\n",
    "tasks = jnp.array([task_to_idx[task] for task in tasks], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageColor\n",
    "\n",
    "# ARC-AGI colors\n",
    "colors = {\n",
    "\t0: \"#000000\",  # Black\n",
    "\t1: \"#0074D9\",  # Blue\n",
    "\t2: \"#FF4136\",  # Red\n",
    "\t3: \"#2ECC40\",  # Green\n",
    "\t4: \"#FFDC00\",  # Yellow\n",
    "\t5: \"#AAAAAA\",  # Grey\n",
    "\t6: \"#F012BE\",  # Fuchsia\n",
    "\t7: \"#FF851B\",  # Orange\n",
    "\t8: \"#7FDBFF\",  # Teal\n",
    "\t9: \"#870C25\",  # Brown\n",
    "}\n",
    "\n",
    "# Convert all ARC colors to RGB using PIL\n",
    "color_lookup = jnp.array([ImageColor.getrgb(hex) for hex in colors.values()]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "tasks = jax.random.permutation(subkey, tasks)\n",
    "ds = jax.random.permutation(subkey, ds)\n",
    "\n",
    "split = int(0.9 * ds.shape[0])\n",
    "\n",
    "train_ds = ds[:split]\n",
    "train_tasks = tasks[:split]\n",
    "\n",
    "test_ds = ds[split:]\n",
    "test_tasks = tasks[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_with_sample(cs, sample, key):\n",
    "\t\"\"\"Create state with sample.\"\"\"\n",
    "\t# Sample input and target\n",
    "\t(\n",
    "\t\t(input_embed_1, output_embed_1),\n",
    "\t\t(input_embed_2, output_embed_2),\n",
    "\t\t(input_embed_3, output_embed_3),\n",
    "\t\t(input_embed, _),\n",
    "\t) = cs.embed_input(sample)\n",
    "\n",
    "\t# Create context\n",
    "\tcontext_1 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_2 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_3 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_4 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_5 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_6 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext = jax.random.choice(\n",
    "\t\tkey, jnp.array([context_1, context_2, context_3, context_4, context_5, context_6])\n",
    "\t)\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\t# state = state.at[..., :3].set(input_embed)\n",
    "\tstate = state.at[..., 3 : 18 + 3].set(context)\n",
    "\tstate = state.at[..., -10:].set(jax.nn.one_hot(sample[-1, 0], num_classes=10))\n",
    "\treturn state, sample[-1, -1]\n",
    "\n",
    "\n",
    "def sample_state(cs, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_flip, key_perm, key_init = jax.random.split(key, 4)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, train_tasks)\n",
    "\tsample = jax.random.choice(key_sample, train_ds)\n",
    "\n",
    "\t# Flip sample half of the time\n",
    "\tflip = jax.random.bernoulli(key_flip, p=0.5)\n",
    "\tsample = jnp.where(flip < 0.5, sample, jnp.flip(sample, axis=-1))\n",
    "\n",
    "\t# Permute colors\n",
    "\tcolor_perm = jnp.concatenate(\n",
    "\t\t[jnp.array([0], dtype=jnp.int32), jax.random.permutation(key_perm, jnp.arange(9)) + 1]\n",
    "\t)\n",
    "\tsample = color_perm[sample]\n",
    "\n",
    "\treturn create_state_with_sample(cs, sample, key_init)\n",
    "\n",
    "\n",
    "def sample_state_test(cs, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_init = jax.random.split(key)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, test_tasks)\n",
    "\tsample = jax.random.choice(key_sample, test_ds)\n",
    "\n",
    "\treturn create_state_with_sample(cs, sample, key_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCNCA(ComplexSystem):\n",
    "\t\"\"\"1D-ARC Neural Cellular Automata  class.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize 1D-ARC NCA.\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\tkernel_size=(3,),\n",
    "\t\t\tfeature_group_count=channel_size,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = ResidualUpdate(\n",
    "\t\t\tnum_spatial_dims=num_spatial_dims,\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\thidden_layer_sizes=hidden_layer_sizes,\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.embed_input = nnx.Embed(num_embeddings=num_embeddings, features=features, rngs=rngs)\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate(\n",
    "\t\t\t[identity_kernel(ndim=num_spatial_dims), grad_kernel(ndim=num_spatial_dims)], axis=-1\n",
    "\t\t)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel.value = kernel\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\t# Extract classification logits\n",
    "\t\tlogits = state[..., -10:]\n",
    "\n",
    "\t\t# Render to RGB\n",
    "\t\trgb = color_lookup[jnp.argmax(logits, axis=-1)]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ARCNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 100_000\n",
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=num_train_steps // 10\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "params = nnx.All(\n",
    "\tnnx.Param,\n",
    "\t# nnx.Not(nnx.PathContains(\"perceive\"))\n",
    ")\n",
    "optimizer = nnx.Optimizer(cs, optimizer, wrt=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(state, output):\n",
    "\t\"\"\"Cross-entropy.\"\"\"\n",
    "\treturn jnp.mean(optax.softmax_cross_entropy_with_integer_labels(state[..., -10:], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(cs, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tkeys = jax.random.split(key, batch_size)\n",
    "\tstate, output = jax.vmap(sample_state, in_axes=(None, 0))(cs, keys)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\tloss = ce(state, output)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, optimizer, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tloss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, params))(cs, key)\n",
    "\toptimizer.update(cs, grad)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cs, eval_ds):\n",
    "\t\"\"\"Compute accuracy.\"\"\"\n",
    "\teval_size = eval_ds.shape[0]\n",
    "\tstate, output = jax.vmap(create_state_with_sample, in_axes=(None, 0, None))(cs, eval_ds, key)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=eval_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\t# Convert logits to symbols\n",
    "\tfinal_state_logits = state[..., -10:]\n",
    "\tfinal_state = jnp.argmax(final_state_logits, axis=-1)\n",
    "\n",
    "\t# Successful if all symbols match in the prediction\n",
    "\treturn jnp.sum(jnp.all(final_state == output, axis=-1)) / eval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss = train_step(cs, optimizer, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\ttest_acc = accuracy(cs, test_ds)\n",
    "\t\ttrain_acc = accuracy(cs, train_ds)\n",
    "\t\tpbar.set_postfix(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"Average Loss\": f\"{avg_loss:.3e}\",\n",
    "\t\t\t\t\"Test Accuracy\": f\"{test_acc:.2%}\",\n",
    "\t\t\t\t\"Train Accuracy\": f\"{train_acc:.2%}\",\n",
    "\t\t\t}\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, num_examples)\n",
    "state_init, output = jax.vmap(sample_state_test, in_axes=(None, 0))(cs, keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state: cs(state, num_steps=num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = jnp.argmax(state_final[..., -10:], axis=-1)\n",
    "success = jnp.all(output_pred == output, axis=-1)\n",
    "\n",
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "# Add titles to each image to indicate success\n",
    "titles = [\"Success\" if s else \"Failure\" for s in success]\n",
    "mediapy.show_images(frames, width=196, height=128, titles=titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
