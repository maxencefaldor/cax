{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-ARC Neural Cellular Automata [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/46_1d_arc_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem, Input, State\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import ResidualUpdate\n",
    "from cax.utils import clip_and_uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_spatial_dims = 1\n",
    "channel_size = 64\n",
    "num_kernels = 2\n",
    "hidden_layer_sizes = (256,)\n",
    "cell_dropout_rate = 0.0\n",
    "\n",
    "num_embeddings = 10  # 10 colors in total\n",
    "features = 3  # embed in rgb\n",
    "\n",
    "num_steps = 64\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "ds_size = 96\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalil-research/1D-ARC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"./1D-ARC/dataset\"\n",
    "\n",
    "\n",
    "def process(input, output):\n",
    "\t\"\"\"Process input and output from dataset.\"\"\"\n",
    "\tinput = jnp.squeeze(jnp.array(input, dtype=jnp.int32))\n",
    "\toutput = jnp.squeeze(jnp.array(output, dtype=jnp.int32))\n",
    "\tassert input.shape == output.shape\n",
    "\n",
    "\tpad_size = ds_size - input.size\n",
    "\tpad_left, pad_right = pad_size // 2, pad_size - pad_size // 2\n",
    "\n",
    "\tinput_padded = jnp.pad(input, (pad_left, pad_right))\n",
    "\toutput_padded = jnp.pad(output, (pad_left, pad_right))\n",
    "\n",
    "\treturn jnp.stack([input_padded, output_padded])\n",
    "\n",
    "\n",
    "ds = []\n",
    "tasks = []\n",
    "for task_idx, task_name in enumerate(os.listdir(ds_path)):\n",
    "\ttask_path = os.path.join(ds_path, task_name)\n",
    "\tfor task_file in os.listdir(task_path):\n",
    "\t\twith open(os.path.join(task_path, task_file)) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tinput_output = jnp.array(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\tprocess(data[\"train\"][0][\"input\"], data[\"train\"][0][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][1][\"input\"], data[\"train\"][1][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][2][\"input\"], data[\"train\"][2][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"test\"][0][\"input\"], data[\"test\"][0][\"output\"]),\n",
    "\t\t\t\t],\n",
    "\t\t\t\tdtype=jnp.int32,\n",
    "\t\t\t)\n",
    "\t\t\ttasks.append(task_name)\n",
    "\t\t\tds.append(input_output)\n",
    "ds = jnp.stack(ds)\n",
    "\n",
    "unique_tasks = list(set(tasks))\n",
    "task_to_idx = {task: idx for idx, task in enumerate(unique_tasks)}\n",
    "tasks = jnp.array([task_to_idx[task] for task in tasks], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageColor\n",
    "\n",
    "# ARC-AGI colors\n",
    "colors = {\n",
    "\t0: \"#000000\",  # Black\n",
    "\t1: \"#0074D9\",  # Blue\n",
    "\t2: \"#FF4136\",  # Red\n",
    "\t3: \"#2ECC40\",  # Green\n",
    "\t4: \"#FFDC00\",  # Yellow\n",
    "\t5: \"#AAAAAA\",  # Grey\n",
    "\t6: \"#F012BE\",  # Fuchsia\n",
    "\t7: \"#FF851B\",  # Orange\n",
    "\t8: \"#7FDBFF\",  # Teal\n",
    "\t9: \"#870C25\",  # Brown\n",
    "}\n",
    "\n",
    "# Convert all ARC colors to RGB using PIL\n",
    "color_lookup = jnp.array([ImageColor.getrgb(hex) for hex in colors.values()]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "tasks = jax.random.permutation(subkey, tasks)\n",
    "ds = jax.random.permutation(subkey, ds)\n",
    "\n",
    "split = int(0.9 * ds.shape[0])\n",
    "\n",
    "train_ds = ds[:split]\n",
    "train_tasks = tasks[:split]\n",
    "\n",
    "test_ds = ds[split:]\n",
    "test_tasks = tasks[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_state_with_sample(cs, sample, key):\n",
    "\t\"\"\"Create state with sample.\"\"\"\n",
    "\t# Sample input and target\n",
    "\t(\n",
    "\t\t(input_embed_1, output_embed_1),\n",
    "\t\t(input_embed_2, output_embed_2),\n",
    "\t\t(input_embed_3, output_embed_3),\n",
    "\t\t(input_embed, _),\n",
    "\t) = cs.embed_input(sample)\n",
    "\n",
    "\t# Create context\n",
    "\tcontext_1 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_2 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_3 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_4 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_5 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_6 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext = jax.random.choice(\n",
    "\t\tkey, jnp.array([context_1, context_2, context_3, context_4, context_5, context_6])\n",
    "\t)\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\t# state = state.at[..., :3].set(input_embed)\n",
    "\tstate = state.at[..., 3 : 18 + 3].set(context)\n",
    "\tstate = state.at[..., -10:].set(jax.nn.one_hot(sample[-1, 0], num_classes=10))\n",
    "\treturn state, sample[-1, -1]\n",
    "\n",
    "\n",
    "def sample_state(cs, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_flip, key_perm, key_init = jax.random.split(key, 4)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, train_tasks)\n",
    "\tsample = jax.random.choice(key_sample, train_ds)\n",
    "\n",
    "\t# Flip sample half of the time\n",
    "\tflip = jax.random.bernoulli(key_flip, p=0.5)\n",
    "\tsample = jnp.where(flip < 0.5, sample, jnp.flip(sample, axis=-1))\n",
    "\n",
    "\t# Permute colors\n",
    "\tcolor_perm = jnp.concatenate(\n",
    "\t\t[jnp.array([0], dtype=jnp.int32), jax.random.permutation(key_perm, jnp.arange(9)) + 1]\n",
    "\t)\n",
    "\tsample = color_perm[sample]\n",
    "\n",
    "\treturn create_state_with_sample(cs, sample, key_init)\n",
    "\n",
    "\n",
    "def sample_state_test(cs, key):\n",
    "\t\"\"\"Sample state with data augmentation.\"\"\"\n",
    "\tkey_sample, key_init = jax.random.split(key)\n",
    "\n",
    "\t# Sample dataset\n",
    "\t_ = jax.random.choice(key_sample, test_tasks)\n",
    "\tsample = jax.random.choice(key_sample, test_ds)\n",
    "\n",
    "\treturn create_state_with_sample(cs, sample, key_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCNCA(ComplexSystem):\n",
    "\t\"\"\"1D-ARC Neural Cellular Automata  class.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize 1D-ARC NCA.\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\tkernel_size=(3,),\n",
    "\t\t\tfeature_group_count=channel_size,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = ResidualUpdate(\n",
    "\t\t\tnum_spatial_dims=num_spatial_dims,\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\thidden_layer_sizes=hidden_layer_sizes,\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.embed_input = nnx.Embed(num_embeddings=num_embeddings, features=features, rngs=rngs)\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate(\n",
    "\t\t\t[identity_kernel(ndim=num_spatial_dims), grad_kernel(ndim=num_spatial_dims)], axis=-1\n",
    "\t\t)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel.value = kernel\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\t# Extract classification logits\n",
    "\t\tlogits = state[..., -10:]\n",
    "\n",
    "\t\t# Render to RGB\n",
    "\t\trgb = color_lookup[jnp.argmax(logits, axis=-1)]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = ARCNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 100_000\n",
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=num_train_steps // 10\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "params = nnx.All(\n",
    "\tnnx.Param,\n",
    "\t# nnx.Not(nnx.PathContains(\"perceive\"))\n",
    ")\n",
    "optimizer = nnx.Optimizer(cs, optimizer, wrt=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(state, output):\n",
    "\t\"\"\"Cross-entropy.\"\"\"\n",
    "\treturn jnp.mean(optax.softmax_cross_entropy_with_integer_labels(state[..., -10:], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(cs, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tkeys = jax.random.split(key, batch_size)\n",
    "\tstate, output = jax.vmap(sample_state, in_axes=(None, 0))(cs, keys)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\tloss = ce(state, output)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, optimizer, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tloss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, params))(cs, key)\n",
    "\toptimizer.update(cs, grad)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(cs, eval_ds):\n",
    "\t\"\"\"Compute accuracy.\"\"\"\n",
    "\teval_size = eval_ds.shape[0]\n",
    "\tstate, output = jax.vmap(create_state_with_sample, in_axes=(None, 0, None))(cs, eval_ds, key)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=eval_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\t# Convert logits to symbols\n",
    "\tfinal_state_logits = state[..., -10:]\n",
    "\tfinal_state = jnp.argmax(final_state_logits, axis=-1)\n",
    "\n",
    "\t# Successful if all symbols match in the prediction\n",
    "\treturn jnp.sum(jnp.all(final_state == output, axis=-1)) / eval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss = train_step(cs, optimizer, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\ttest_acc = accuracy(cs, test_ds)\n",
    "\t\ttrain_acc = accuracy(cs, train_ds)\n",
    "\t\tpbar.set_postfix(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"Average Loss\": f\"{avg_loss:.3e}\",\n",
    "\t\t\t\t\"Test Accuracy\": f\"{test_acc:.2%}\",\n",
    "\t\t\t\t\"Train Accuracy\": f\"{train_acc:.2%}\",\n",
    "\t\t\t}\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, num_examples)\n",
    "state_init, output = jax.vmap(sample_state_test, in_axes=(None, 0))(cs, keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state: cs(state, num_steps=num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pred = jnp.argmax(state_final[..., -10:], axis=-1)\n",
    "success = jnp.all(output_pred == output, axis=-1)\n",
    "\n",
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "# Add titles to each image to indicate success\n",
    "titles = [\"Success\" if s else \"Failure\" for s in success]\n",
    "mediapy.show_images(frames, width=196, height=128, titles=titles)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
