{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Self-classifying MNIST Digits [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/44_self_classifying_mnist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "import torchvision\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem, Input, State\n",
    "from cax.core.perceive import ConvPerceive\n",
    "from cax.core.update import NCAUpdate\n",
    "from cax.nn.pool import Pool\n",
    "from cax.utils import clip_and_uint8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "spatial_dims = (28, 28)\n",
    "channel_size = 20\n",
    "perception_size = 80\n",
    "hidden_layers_sizes = (80,)\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "num_steps = 20\n",
    "pool_size = 1_024\n",
    "batch_size = 16\n",
    "learning_rate = 1e-3\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST dataset\n",
    "ds_train = torchvision.datasets.MNIST(root=\"./data\", train=True, download=True)\n",
    "ds_test = torchvision.datasets.MNIST(root=\"./data\", train=False, download=True)\n",
    "\n",
    "# Convert to jax.Array\n",
    "x_train = jnp.array([x.resize(spatial_dims) for x, _ in ds_train])[..., None] / 255\n",
    "x_test = jnp.array([x.resize(spatial_dims) for x, _ in ds_test])[..., None] / 255\n",
    "\n",
    "y_integer_train = jnp.array([y for _, y in ds_train], dtype=jnp.int32)\n",
    "y_integer_test = jnp.array([y for _, y in ds_test], dtype=jnp.int32)\n",
    "\n",
    "# Visualize\n",
    "mediapy.show_images(x_train[:8], width=128, height=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmt: off\n",
    "color_lookup = jnp.array(\n",
    "\t[\n",
    "\t\t[128, 0, 0],      # Digit 0\n",
    "\t\t[230, 25, 75],    # Digit 1\n",
    "\t\t[70, 240, 240],   # Digit 2\n",
    "\t\t[210, 245, 60],   # Digit 3\n",
    "\t\t[250, 190, 190],  # Digit 4\n",
    "\t\t[170, 110, 40],   # Digit 5\n",
    "\t\t[170, 255, 195],  # Digit 6\n",
    "\t\t[165, 163, 159],  # Digit 7\n",
    "\t\t[0, 128, 128],    # Digit 8\n",
    "\t\t[128, 128, 0],    # Digit 9\n",
    "\t\t[0, 0, 0],        # Default\n",
    "\t\t[255, 255, 255],  # Background\n",
    "\t]\n",
    ") / 255\n",
    "\n",
    "\n",
    "def compute_y(x, y_integer):\n",
    "\t\"\"\"Compute the target y from image and integer label.\"\"\"\n",
    "\tmask = x >= 0.1\n",
    "\treturn jnp.where(mask, jax.nn.one_hot(y_integer, 10), 0.0)\n",
    "\n",
    "\n",
    "def render(x, y):\n",
    "\t\"\"\"Render x and y to RGB.\"\"\"\n",
    "\t# Mask for digit and background pixels\n",
    "\tis_digit = (x > 0.1).astype(jnp.float32)\n",
    "\tis_not_digit = 1.0 - is_digit\n",
    "\n",
    "\t# Apply the mask to the probabilities\n",
    "\ty = is_digit * y\n",
    "\n",
    "\tblack_and_white = jnp.concatenate([is_digit, is_not_digit], axis=-1) * 0.01\n",
    "\ty = jnp.concatenate([y, black_and_white], axis=-1)\n",
    "\n",
    "\treturn color_lookup[jnp.argmax(y, axis=-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = jax.vmap(compute_y)(x_train, y_integer_train)\n",
    "y_test = jax.vmap(compute_y)(x_test, y_integer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize different colored digits\n",
    "digits = []\n",
    "for i in range(10):\n",
    "\tmask = y_integer_train == i\n",
    "\tidx = jnp.argmax(mask)\n",
    "\tdigits.append(render(x_train[idx], y_train[idx]))\n",
    "\n",
    "mediapy.show_images(digits, width=64, height=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfClassifyingNCA(ComplexSystem):\n",
    "\t\"\"\"Self-Classifying Neural Cellular Automata.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize Self-Classifying NCA.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\trngs: rng key.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=perception_size,\n",
    "\t\t\tuse_bias=True,\n",
    "\t\t\tactivation_fn=nnx.relu,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = NCAUpdate(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=perception_size,\n",
    "\t\t\thidden_layer_sizes=hidden_layers_sizes,\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\t\"\"\"Perform a single step.\"\"\"\n",
    "\t\t# Extract x\n",
    "\t\tx = state[..., -1:]\n",
    "\n",
    "\t\t# Step\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\t# Override\n",
    "\t\tnext_state = next_state.at[..., -1:].set(x)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state: State):\n",
    "\t\t\"\"\"Render state to RGB frame.\"\"\"\n",
    "\t\t# Extract x and classification logits\n",
    "\t\tx = state[..., -1:]\n",
    "\t\tlogits = state[..., :10]\n",
    "\n",
    "\t\t# Render the image and the logits to RGB\n",
    "\t\trgb = render(x, logits)\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = SelfClassifyingNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state(key):\n",
    "\t\"\"\"Sample a state with a random image.\"\"\"\n",
    "\t# Init state\n",
    "\tstate = jnp.zeros(x_train.shape[1:3] + (channel_size,))\n",
    "\n",
    "\t# Sample random image\n",
    "\tx_idx = jax.random.choice(key, x_train.shape[0])\n",
    "\tx = x_train[x_idx]\n",
    "\n",
    "\t# Set image in state\n",
    "\tstate = state.at[..., -1:].set(x)\n",
    "\treturn state, x_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "keys = jax.random.split(subkey, pool_size)\n",
    "state, x_idx = jax.vmap(sample_state)(keys)\n",
    "\n",
    "pool = Pool.create({\"state\": state, \"x_idx\": x_idx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.01 * learning_rate, transition_steps=100_000\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "optimizer = nnx.Optimizer(cs, optimizer, wrt=nnx.Param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2(state, y):\n",
    "\t\"\"\"L2.\"\"\"\n",
    "\tl2_loss = jnp.sum(jnp.square(state[..., :10] - y), axis=(-1, -2, -3)) / 2\n",
    "\treturn jnp.mean(l2_loss)\n",
    "\n",
    "\n",
    "def ce(state, y):\n",
    "\t\"\"\"Cross-entropy.\"\"\"\n",
    "\tinteger_label = jnp.argmax(y, axis=-1)\n",
    "\treturn jnp.mean(optax.softmax_cross_entropy_with_integer_labels(state[..., :10], integer_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(cs, state, y):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\tloss = l2(state, y)\n",
    "\treturn loss, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, optimizer, pool, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tsample_key, sample_state_key = jax.random.split(key)\n",
    "\n",
    "\t# Sample from pool\n",
    "\tpool_idx, batch = pool.sample(sample_key, batch_size=batch_size)\n",
    "\tcurrent_state = batch[\"state\"]\n",
    "\tcurrent_x_idx = batch[\"x_idx\"]\n",
    "\n",
    "\t# A quarter of the batch is replaced with new images\n",
    "\tnew_state, new_x_idx = sample_state(sample_state_key)\n",
    "\tcurrent_state = current_state.at[: batch_size // 4].set(new_state)\n",
    "\tcurrent_x_idx = current_x_idx.at[: batch_size // 4].set(new_x_idx)\n",
    "\n",
    "\t# Get images\n",
    "\tcurrent_y = y_train[current_x_idx]\n",
    "\n",
    "\t(loss, current_state), grad = nnx.value_and_grad(loss_fn, has_aux=True)(\n",
    "\t\tcs, current_state, current_y\n",
    "\t)\n",
    "\toptimizer.update(cs, grad)\n",
    "\n",
    "\tpool = pool.update(pool_idx, {\"state\": current_state, \"x_idx\": current_x_idx})\n",
    "\treturn loss, pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 8_192\n",
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss, pool = train_step(cs, optimizer, pool, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\tpbar.set_postfix({\"Average Loss\": f\"{avg_loss:.3e}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, num_examples)\n",
    "state_init, _ = jax.vmap(sample_state)(keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state: cs(state, num_steps=4 * num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_videos(frames, width=128, height=128, codec=\"gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
