{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growing Conditional Neural Cellular Automata [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/41_growing_conditional_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "import PIL\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem, Input, State\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import NCAUpdate\n",
    "from cax.nn.pool import Pool\n",
    "from cax.utils import clip_and_uint8, rgba_to_rgb\n",
    "from cax.utils.emoji import get_emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "channel_size = 32\n",
    "num_kernels = 3\n",
    "hidden_size = 256\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "num_steps = 64\n",
    "pool_size = 1_024\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "\n",
    "emojis = \"ðŸ¶ðŸ±ðŸ­ðŸ¹ðŸ°ðŸ¦ŠðŸ»ðŸ¼\"\n",
    "size = 40\n",
    "pad_width = 16\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_from_emoji(emoji: str) -> jax.Array:\n",
    "\t\"\"\"Get target y from an emoji.\"\"\"\n",
    "\temoji_pil = get_emoji(emoji)\n",
    "\temoji_pil = emoji_pil.resize((size, size), resample=PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "\ty = jnp.array(emoji_pil, dtype=jnp.float32) / 255.0\n",
    "\ty = jnp.pad(y, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)))\n",
    "\n",
    "\treturn y\n",
    "\n",
    "\n",
    "y = jnp.array([get_y_from_emoji(emoji) for emoji in emojis])\n",
    "z = jnp.eye(y.shape[0])\n",
    "\n",
    "mediapy.show_images(y, width=128, height=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrowingConditionalNCA(ComplexSystem):\n",
    "\t\"\"\"Growing Conditional Neural Cellular Automata class.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize Growing Conditional NCA.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\trngs: rng key.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\tfeature_group_count=channel_size,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = NCAUpdate(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=y.shape[0] + num_kernels * channel_size,\n",
    "\t\t\thidden_layer_sizes=(hidden_size,),\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate([identity_kernel(ndim=2), grad_kernel(ndim=2)], axis=-1)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel.value = kernel\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\t# Broadcast the input vector to match the state shape\n",
    "\t\tinput_shape = (*state.shape[:-1], input.shape[-1])\n",
    "\t\tinput = jnp.broadcast_to(input[..., None, None, :], input_shape)\n",
    "\n",
    "\t\t# Step\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\t\trgb = rgba_to_rgb(rgba)\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render_rgba(self, state):\n",
    "\t\t\"\"\"Render state to RGBA.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = GrowingConditionalNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state(key):\n",
    "\t\"\"\"Sample a state with a single alive cell.\"\"\"\n",
    "\tspatial_dims = y.shape[1:3]\n",
    "\n",
    "\t# Init state\n",
    "\tstate = jnp.zeros(spatial_dims + (channel_size,))\n",
    "\tmid = tuple(size // 2 for size in spatial_dims)\n",
    "\n",
    "\t# Set the center cell to alive\n",
    "\tstate = state.at[mid[0], mid[1], -1].set(1.0)\n",
    "\n",
    "\t# Sample a random target y\n",
    "\ty_idx = jax.random.choice(key, y.shape[0])\n",
    "\treturn state, y_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "keys = jax.random.split(subkey, pool_size)\n",
    "state, y_idx = jax.vmap(lambda key: sample_state(key))(keys)\n",
    "\n",
    "pool = Pool.create({\"state\": state, \"y_idx\": y_idx})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=50_000\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "update_params = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "optimizer = nnx.Optimizer(cs, optimizer, wrt=update_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(state, y):\n",
    "\t\"\"\"Mean Squared Error.\"\"\"\n",
    "\treturn jnp.mean(jnp.square(state[..., -4:] - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(cs, state, z, y, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tnnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state, z: cs(state, z, num_steps=num_steps, sow=True),\n",
    "\t\t\tin_axes=(state_axes, 0, 0),\n",
    "\t\t)\n",
    "\t)(cs, state, z)\n",
    "\n",
    "\t# Get intermediate states\n",
    "\tintermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "\tstate = intermediates.state.value[0]\n",
    "\n",
    "\t# Sample a random step\n",
    "\tidx = jax.random.randint(key, (batch_size,), num_steps // 2, num_steps)\n",
    "\tstate = state[jnp.arange(batch_size), idx]\n",
    "\n",
    "\tloss = mse(state, y)\n",
    "\treturn loss, state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, optimizer, pool, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tsample_key, sample_state_key, loss_key = jax.random.split(key, 3)\n",
    "\n",
    "\t# Sample from pool\n",
    "\tpool_idx, batch = pool.sample(sample_key, batch_size=batch_size)\n",
    "\tcurrent_state = batch[\"state\"]\n",
    "\tcurrent_y_idx = batch[\"y_idx\"]\n",
    "\tcurrent_y = y[current_y_idx]\n",
    "\n",
    "\t# Sort by descending loss\n",
    "\tsort_idx = jnp.argsort(jax.vmap(mse)(current_state, current_y), descending=True)\n",
    "\tpool_idx = pool_idx[sort_idx]\n",
    "\tcurrent_state = current_state[sort_idx]\n",
    "\tcurrent_y_idx = current_y_idx[sort_idx]\n",
    "\n",
    "\t# Sample a new state to replace the worst\n",
    "\tnew_state, new_y_idx = sample_state(sample_state_key)\n",
    "\tcurrent_state = current_state.at[0].set(new_state)\n",
    "\tcurrent_y_idx = current_y_idx.at[0].set(new_y_idx)\n",
    "\tcurrent_y = y[current_y_idx]\n",
    "\tcurrent_z = z[current_y_idx]\n",
    "\n",
    "\t(loss, current_state), grad = nnx.value_and_grad(\n",
    "\t\tloss_fn, has_aux=True, argnums=nnx.DiffState(0, update_params)\n",
    "\t)(cs, current_state, current_z, current_y, loss_key)\n",
    "\toptimizer.update(cs, grad)\n",
    "\n",
    "\tpool = pool.update(pool_idx, {\"state\": current_state, \"y_idx\": current_y_idx})\n",
    "\treturn loss, pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 8_192\n",
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss, pool = train_step(cs, optimizer, pool, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\tpbar.set_postfix({\"Average Loss\": f\"{avg_loss:.3e}\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "keys = jax.random.split(subkey, y.shape[0])\n",
    "state_init, _ = jax.vmap(sample_state)(keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=y.shape[0])(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state, z: cs(state, z, num_steps=2 * num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0, 0),\n",
    "\t)\n",
    ")(cs, state_init, z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "frames_final = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)\n",
    "\n",
    "frames_final_rgba = nnx.vmap(\n",
    "\tlambda cs, state: cs.render_rgba(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediapy.show_images(frames_final_rgba, width=128, height=128)\n",
    "mediapy.show_videos(frames, width=128, height=128, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dog-Panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latent encoding\n",
    "z_dog_panda = jnp.array([0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5])\n",
    "\n",
    "# Sample initial state\n",
    "key, subkey = jax.random.split(key)\n",
    "state_init, _ = sample_state(subkey)\n",
    "\n",
    "# Run\n",
    "cs(state_init, z_dog_panda, num_steps=2 * num_steps, sow=True)\n",
    "\n",
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]\n",
    "\n",
    "# Visualize\n",
    "states = jnp.concatenate([state_init[None], states])\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_video(frames, width=128, height=128, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fox-Panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latent encoding\n",
    "z_fox_panda = jnp.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.5])\n",
    "\n",
    "# Sample initial state\n",
    "key, subkey = jax.random.split(key)\n",
    "state_init, _ = sample_state(subkey)\n",
    "\n",
    "# Run\n",
    "cs(state_init, z_fox_panda, num_steps=2 * num_steps, sow=True)\n",
    "\n",
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]\n",
    "\n",
    "# Visualize\n",
    "states = jnp.concatenate([state_init[None], states])\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_video(frames, width=128, height=128, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cat-Panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define two target images\n",
    "cat_idx = 1\n",
    "panda_idx = 7\n",
    "\n",
    "# Interpolate between the two latent encodings\n",
    "num_interpolations = 8\n",
    "alphas = jnp.linspace(0.0, 1.0, num_interpolations)\n",
    "z_interpolation = jnp.array([(1.0 - alpha) * z[cat_idx] + alpha * z[panda_idx] for alpha in alphas])\n",
    "\n",
    "# Sample initial state\n",
    "key, subkey = jax.random.split(key)\n",
    "state_init, _ = sample_state(subkey)\n",
    "\n",
    "# Run\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "final_states = nnx.split_rngs(splits=alphas.shape[0])(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state, z: cs(state, z, num_steps=2 * num_steps),\n",
    "\t\tin_axes=(state_axes, None, 0),\n",
    "\t)\n",
    ")(cs, state_init, z_interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render_rgba(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, final_states)\n",
    "\n",
    "mediapy.show_images(frames, width=128, height=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
