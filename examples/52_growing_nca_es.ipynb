{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growing Neural Cellular Automata with Evolution Strategies [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/40_growing_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "import PIL\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import NCAUpdate\n",
    "from cax.types import Input, State\n",
    "from cax.utils import clip_and_uint8, get_emoji, rgba_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "channel_size = 16\n",
    "num_kernels = 3\n",
    "hidden_size = 128\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "num_steps = 90\n",
    "population_size = 512\n",
    "batch_size = 1\n",
    "\n",
    "emoji = \"ðŸ¦Ž\"\n",
    "size = 40\n",
    "pad_width = 4\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_from_emoji(emoji: str) -> jax.Array:\n",
    "\t\"\"\"Get target y from an emoji.\"\"\"\n",
    "\temoji_pil = get_emoji(emoji)\n",
    "\temoji_pil = emoji_pil.resize((size, size), resample=PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "\ty = jnp.array(emoji_pil, dtype=jnp.float32) / 255.0\n",
    "\ty = jnp.pad(y, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)))\n",
    "\n",
    "\treturn y\n",
    "\n",
    "\n",
    "y = get_y_from_emoji(emoji)\n",
    "\n",
    "mediapy.show_image(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrowingNCA(ComplexSystem):\n",
    "\t\"\"\"Growing Neural Cellular Automata class.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize Growing NCA.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\trngs: rng key.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\tfeature_group_count=channel_size,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = NCAUpdate(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\thidden_layer_sizes=(hidden_size,),\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate([identity_kernel(ndim=2), grad_kernel(ndim=2)], axis=-1)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel.value = kernel\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\t\trgb = rgba_to_rgb(rgba)\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render_rgba(self, state):\n",
    "\t\t\"\"\"Render state to RGBA.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = GrowingNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state():\n",
    "\t\"\"\"Sample a state with a single alive cell.\"\"\"\n",
    "\tspatial_dims = y.shape[:2]\n",
    "\n",
    "\t# Init state\n",
    "\tstate = jnp.zeros(spatial_dims + (channel_size,))\n",
    "\n",
    "\t# Set the center cell to alive\n",
    "\tmid = tuple(size // 2 for size in spatial_dims)\n",
    "\treturn state.at[mid[0], mid[1], -1].set(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_filter = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "solution = nnx.state(cs, trainable_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax.algorithms import Open_ES as ES\n",
    "\n",
    "learning_rate = 0.001\n",
    "std_init = 0.001\n",
    "\n",
    "es = ES(\n",
    "\tpopulation_size=population_size,\n",
    "\tsolution=solution,\n",
    "\toptimizer=optax.adam(learning_rate=learning_rate),\n",
    "\tstd_schedule=optax.constant_schedule(std_init),\n",
    ")\n",
    "\n",
    "es_params = es.default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "es_state = es.init(subkey, solution, es_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(state):\n",
    "\t\"\"\"Mean Squared Error.\"\"\"\n",
    "\treturn jnp.mean(jnp.square(state[..., -4:] - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(cs, state, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tnnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps, sow=True),\n",
    "\t\t\tin_axes=(state_axes, None),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\t# Get intermediate states\n",
    "\tintermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "\tstate = intermediates.state.value[0]\n",
    "\n",
    "\tloss = mse(state[-32:])\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, es_state, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tkey, key_ask, key_eval, key_tell = jax.random.split(key, 4)\n",
    "\n",
    "\tstate = sample_state()\n",
    "\n",
    "\t# Generate a set of candidate solutions to evaluate\n",
    "\tpopulation, es_state = es.ask(key_ask, es_state, es_params)\n",
    "\n",
    "\t# Evaluate the fitness of the population\n",
    "\tnnx.update(cs, population)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({trainable_filter: 0, ...: None})\n",
    "\tfitness = nnx.vmap(\n",
    "\t\tloss_fn,\n",
    "\t\tin_axes=(state_axes, None, None),\n",
    "\t)(cs, state, key_eval)\n",
    "\n",
    "\t# Update the evolution strategy\n",
    "\tes_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)\n",
    "\n",
    "\treturn es_state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 1024 * 10\n",
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_generations), desc=\"Evolution\", unit=\"generation\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tes_state, metrics = train_step(cs, es_state, subkey)\n",
    "\n",
    "\tlosses.append(metrics[\"best_fitness_in_generation\"])\n",
    "\tif i % print_interval == 0 or i == num_generations - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\tpbar.set_postfix({\"Average Loss\": f\"{avg_loss:.3e}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = es.get_mean(es_state)\n",
    "nnx.update(cs, trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "state_init = jax.vmap(lambda _: sample_state())(jnp.zeros(num_examples))\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state_init: cs(state_init, num_steps=num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_final = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)\n",
    "frames_final_rgba = nnx.vmap(\n",
    "\tlambda cs, state: cs.render_rgba(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)\n",
    "\n",
    "mediapy.show_images(frames_final, width=128, height=128)\n",
    "mediapy.show_images(frames_final_rgba, width=128, height=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, states: cs.render(states),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_videos(frames, width=128, height=128, codec=\"gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
