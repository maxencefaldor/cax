{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Growing Neural Cellular Automata with Evolution Strategies [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/40_growing_nca.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "import PIL\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from cax.core import ComplexSystem, Input, State\n",
    "from cax.core.perceive import ConvPerceive, grad_kernel, identity_kernel\n",
    "from cax.core.update import NCAUpdate\n",
    "from cax.utils import clip_and_uint8, get_emoji, rgba_to_rgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "channel_size = 16\n",
    "num_kernels = 3\n",
    "hidden_size = 128\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "num_steps = 90\n",
    "population_size = 512\n",
    "batch_size = 1\n",
    "\n",
    "emoji = \"ðŸ¦Ž\"\n",
    "size = 40\n",
    "pad_width = 4\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_from_emoji(emoji: str) -> jax.Array:\n",
    "\t\"\"\"Get target y from an emoji.\"\"\"\n",
    "\temoji_pil = get_emoji(emoji)\n",
    "\temoji_pil = emoji_pil.resize((size, size), resample=PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "\ty = jnp.array(emoji_pil, dtype=jnp.float32) / 255.0\n",
    "\ty = jnp.pad(y, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)))\n",
    "\n",
    "\treturn y\n",
    "\n",
    "\n",
    "y = get_y_from_emoji(emoji)\n",
    "\n",
    "mediapy.show_image(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrowingNCA(ComplexSystem):\n",
    "\t\"\"\"Growing Neural Cellular Automata class.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize Growing NCA.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\trngs: rng key.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\tfeature_group_count=channel_size,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\t\tself.update = NCAUpdate(\n",
    "\t\t\tchannel_size=channel_size,\n",
    "\t\t\tperception_size=num_kernels * channel_size,\n",
    "\t\t\thidden_layer_sizes=(hidden_size,),\n",
    "\t\t\tcell_dropout_rate=cell_dropout_rate,\n",
    "\t\t\tzeros_init=True,\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\t\t# Initialize kernel with sobel filters\n",
    "\t\tkernel = jnp.concatenate([identity_kernel(ndim=2), grad_kernel(ndim=2)], axis=-1)\n",
    "\t\tkernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "\t\tself.perceive.conv.kernel.value = kernel\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\t\trgb = rgba_to_rgb(rgba)\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render_rgba(self, state):\n",
    "\t\t\"\"\"Render state to RGBA.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = GrowingNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = nnx.state(cs, nnx.Param)\n",
    "print(\"Number of params:\", sum(x.size for x in jax.tree.leaves(params)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state():\n",
    "\t\"\"\"Sample a state with a single alive cell.\"\"\"\n",
    "\tspatial_dims = y.shape[:2]\n",
    "\n",
    "\t# Init state\n",
    "\tstate = jnp.zeros(spatial_dims + (channel_size,))\n",
    "\n",
    "\t# Set the center cell to alive\n",
    "\tmid = tuple(size // 2 for size in spatial_dims)\n",
    "\treturn state.at[mid[0], mid[1], -1].set(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_filter = nnx.All(nnx.Param, nnx.PathContains(\"update\"))\n",
    "solution = nnx.state(cs, trainable_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evosax.algorithms import Open_ES as ES\n",
    "\n",
    "learning_rate = 0.001\n",
    "std_init = 0.001\n",
    "\n",
    "es = ES(\n",
    "\tpopulation_size=population_size,\n",
    "\tsolution=solution,\n",
    "\toptimizer=optax.adam(learning_rate=learning_rate),\n",
    "\tstd_schedule=optax.constant_schedule(std_init),\n",
    ")\n",
    "\n",
    "es_params = es.default_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "es_state = es.init(subkey, solution, es_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(state):\n",
    "\t\"\"\"Mean Squared Error.\"\"\"\n",
    "\treturn jnp.mean(jnp.square(state[..., -4:] - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(cs, state, key):\n",
    "\t\"\"\"Loss function.\"\"\"\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "\tnnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda cs, state: cs(state, num_steps=num_steps, sow=True),\n",
    "\t\t\tin_axes=(state_axes, None),\n",
    "\t\t)\n",
    "\t)(cs, state)\n",
    "\n",
    "\t# Get intermediate states\n",
    "\tintermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "\tstate = intermediates.state.value[0]\n",
    "\n",
    "\tloss = mse(state[-32:])\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(cs, es_state, key):\n",
    "\t\"\"\"Train step.\"\"\"\n",
    "\tkey, key_ask, key_eval, key_tell = jax.random.split(key, 4)\n",
    "\n",
    "\tstate = sample_state()\n",
    "\n",
    "\t# Generate a set of candidate solutions to evaluate\n",
    "\tpopulation, es_state = es.ask(key_ask, es_state, es_params)\n",
    "\n",
    "\t# Evaluate the fitness of the population\n",
    "\tnnx.update(cs, population)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({trainable_filter: 0, ...: None})\n",
    "\tfitness = nnx.vmap(\n",
    "\t\tloss_fn,\n",
    "\t\tin_axes=(state_axes, None, None),\n",
    "\t)(cs, state, key_eval)\n",
    "\n",
    "\t# Update the evolution strategy\n",
    "\tes_state, metrics = es.tell(key_tell, population, fitness, es_state, es_params)\n",
    "\n",
    "\treturn es_state, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_generations = 1024 * 10\n",
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_generations), desc=\"Evolution\", unit=\"generation\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tes_state, metrics = train_step(cs, es_state, subkey)\n",
    "\n",
    "\tlosses.append(metrics[\"best_fitness_in_generation\"])\n",
    "\tif i % print_interval == 0 or i == num_generations - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\tpbar.set_postfix({\"Average Loss\": f\"{avg_loss:.3e}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_params = es.get_mean(es_state)\n",
    "nnx.update(cs, trainable_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_examples = 8\n",
    "\n",
    "state_init = jax.vmap(lambda _: sample_state())(jnp.zeros(num_examples))\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state_init: cs(state_init, num_steps=num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames_final = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)\n",
    "frames_final_rgba = nnx.vmap(\n",
    "\tlambda cs, state: cs.render_rgba(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, state_final)\n",
    "\n",
    "mediapy.show_images(frames_final, width=128, height=128)\n",
    "mediapy.show_images(frames_final_rgba, width=128, height=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, states: cs.render(states),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_videos(frames, width=128, height=128, codec=\"gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
