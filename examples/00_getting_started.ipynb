{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAX: Cellular Automata Accelerated in JAX [![Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/maxencefaldor/cax/blob/main/examples/00_getting_started.ipynb) [![Paper](http://img.shields.io/badge/paper-arxiv.2410.02651-B31B1B.svg)](https://arxiv.org/abs/2410.02651)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAX is a high-performance and flexible open-source library designed to **accelerate artificial life research**. ðŸ§¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"../docs/cax.png\" alt=\"logo\" width=\"300\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract\n",
    "\n",
    "Cellular automata have become a cornerstone for investigating emergence and self-organization across diverse scientific disciplines. However, the absence of a hardware-accelerated cellular automata library limits the exploration of new research directions, hinders collaboration, and impedes reproducibility. In this work, we introduce CAX (Cellular Automata Accelerated in JAX), a high-performance and flexible open-source library designed to accelerate cellular automata research. CAX delivers cutting-edge performance through hardware acceleration while maintaining flexibility through its modular architecture, intuitive API, and support for both discrete and continuous cellular automata in arbitrary dimensions. We demonstrate CAX's performance and flexibility through a wide range of benchmarks and applications. From classic models like elementary cellular automata and Conway's Game of Life to advanced applications such as growing neural cellular automata and self-classifying MNIST digits, CAX speeds up simulations up to 2,000 times faster. Furthermore, we demonstrate CAX's potential to accelerate research by presenting a collection of three novel cellular automata experiments, each implemented in just a few lines of code thanks to the library's modular architecture. Notably, we show that a simple one-dimensional cellular automaton can outperform GPT-4 on the 1D-ARC challenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Self-autoencoding MNIST Digits](../docs/ca_types.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cellular Automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A *cellular automaton* is a simple model of computation consisting of a regular grid of cells, each in a particular state. The grid can be in any finite number of dimensions. For each cell, a set of cells called its *neighborhood* is defined relative to the specified cell. The grid is updated at discrete time steps according to a fixed rule that determines the new state of each cell based on its current state and the states of the cells in its neighborhood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAX Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAX introduces a unifying framework for *all cellular automata types*. This flexible architecture is\n",
    "built upon two key components: the **perceive** module and the **update** module. Together, these modules define the local rule of the CA. At each time step, this local rule is applied uniformly to all cells in the grid, generating the next global state of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![CAX architecture](../docs/architecture.png)\n",
    "\n",
    "Figure adapted from \"Growing Neural Cellular Automata\", Mordvintsev et al. (2020), under CC-BY 4.0 license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAX's architecture introduces the novel concept of **Controllable Cellular Automata** that extend the capabilities of traditional CAs by making them responsive to external inputs, akin to recurrent neural networks processing sequential data, see Figure above. Controllable cellular automata bridge the gap between recurrent convolutional neural networks and cellular automata, opening up new possibilities for modeling complex systems that exhibit both autonomous emergent behavior and responsiveness to external control."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For CA experiments with external inputs, see [examples/41_growing_conditional_nca.ipynb](../examples/41_growing_conditional_nca.ipynb) and [examples/42_growing_unsupervised_nca.ipynb](../examples/42_growing_unsupervised_nca.ipynb) for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's dive in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will explore how to use CAX to both:\n",
    "- instantiate classic cellular automata like the Game of Life and\n",
    "- create custom cellular automata from scratch.\n",
    "\n",
    "You'll learn the fundamental concepts and implementation techniques that make CAX a powerful framework for cellular automata experimentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.11 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "from flax import nnx\n",
    "\n",
    "from cax.types import Input, State"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore ready-to-use cellular automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we'll demonstrate the basic usage of CAX with pre-implemented cellular automata. We'll instantiate Conway's Game of Life and visualize a glider pattern, showing how easily you can get started with existing systems in the library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we set up the configuration, including seed, spatial dimensions and the number of steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_steps = 128\n",
    "spatial_dims = (32, 32)\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we instantiate Conway's Game of Life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cax.cs.life import Life\n",
    "\n",
    "birth, survival = Life.birth_survival_from_string(\"B3/S23\")\n",
    "cs = Life(birth=birth, survival=survival, rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnx.display(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample initial state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we define a function to sample an initial state, which is essential for running a system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state():\n",
    "\t\"\"\"Sample a state with a glider for the Game of Life.\"\"\"\n",
    "\tstate = jnp.zeros((*spatial_dims, 1))\n",
    "\n",
    "\tmid_x, mid_y = spatial_dims[0] // 2, spatial_dims[1] // 2\n",
    "\tglider = jnp.array(\n",
    "\t\t[\n",
    "\t\t\t[0.0, 1.0, 0.0],\n",
    "\t\t\t[0.0, 0.0, 1.0],\n",
    "\t\t\t[1.0, 1.0, 1.0],\n",
    "\t\t]\n",
    "\t)\n",
    "\treturn state.at[mid_x : mid_x + 3, mid_y : mid_y + 3, 0].set(glider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an initial state and the system, we can simulate for `num_steps`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_init = sample_state()\n",
    "state_final = cs(state_init, num_steps=num_steps, sow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start from `state_init` sampled with our function `sample_state`, and then we apply the complex system `cs` for `num_steps` to get the `state_final`.\n",
    "\n",
    "However, to visualize the evolution of the complex system, we need to have access to the intermediate states. But how do we do that?\n",
    "\n",
    "To do that, we use the `nnx.sow` utilities from Flax. The `sow` mechanism allows you to collect intermediate values during computation by \"sowing\" them into a collection that can be retrieved later. For more details, see the [official Flax documentation](https://flax.readthedocs.io/en/latest/guides/pytree.html#sow).\n",
    "\n",
    "Implemented complex systems, such as Life, already offer the possibility to sow the intermediate states of the system during the evolution, and can be accessed with the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the initial state `state_init`, as well as the intermediate states `states`, we can visualize the evolution of the complex system.\n",
    "\n",
    "All complex systems must include a `render` method to convert a state into an RGB frame. For the Game of Life, a ready-to-use `render` method is provided, allowing you to easily generate a frame with a simple call: `frame = cs.render(state)`.\n",
    "\n",
    "Enjoy! ðŸ‘¾"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[None], states])  # concatenate initial state with other states\n",
    "frames = nnx.vmap(  # render each frame\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_video(frames, width=256, height=256, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While visualizing the evolution of states can produce captivating simulations, we often also want to track additional metrics to better understand how the system evolves over time.\n",
    "\n",
    "By default, CAX enables to sow the states encountered during the systemâ€™s evolution. However, this behavior is highly customizable. In this section, weâ€™ll explore how to create a tailored metrics function to sow custom metrics suited to your needs.\n",
    "\n",
    "First, let's define a metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_fn(state, next_state, perception):\n",
    "\t\"\"\"Metrics function for the Game of Life.\"\"\"\n",
    "\tneighbors_alive_count = perception[..., 1:2]\n",
    "\treturn {\n",
    "\t\t\"num_neighbors\": jnp.mean(neighbors_alive_count),\n",
    "\t\t\"growth_rate\": jnp.sum(next_state) - jnp.sum(state),\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we will need to create a custom Life class, that sow our desired metrics during the step function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLife(Life):\n",
    "\t\"\"\"Custom Life class with custom metrics.\"\"\"\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tmetrics = metrics_fn(state, next_state, perception)\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\t\t\tself.sow(nnx.Intermediate, \"metrics\", metrics)\n",
    "\n",
    "\t\treturn next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's instantiate the Game of Life with this custom metrics function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CustomLife(birth=birth, survival=survival, rngs=rngs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time, we will generate a state composed of randomly initialized cells, drawn from a Bernoulli distribution where each cell has a 0.1 probability of being alive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state(key, p=0.1):\n",
    "\t\"\"\"Sample a random state for the Game of Life.\"\"\"\n",
    "\treturn jax.random.bernoulli(key, p=p, shape=(*spatial_dims, 1)).astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "state_init = sample_state(subkey)\n",
    "state_final = cs(state_init, num_steps=num_steps, sow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and visualize:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]\n",
    "metrics = intermediates.metrics.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[None], states])\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_video(frames, width=256, height=256, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also plot the number of alive neighbors and growth rate over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the metrics\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "axes[0].plot(metrics[\"num_neighbors\"])\n",
    "axes[0].set_title(\"Number of Neighbors Alive\")\n",
    "axes[0].set_xlabel(\"Time Step\")\n",
    "axes[0].set_ylabel(\"Number of Neighbors Alive\")\n",
    "\n",
    "axes[1].plot(metrics[\"growth_rate\"])\n",
    "axes[1].set_title(\"Growth Rate\")\n",
    "axes[1].set_xlabel(\"Time Step\")\n",
    "axes[1].set_ylabel(\"Growth Rate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running parallel simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `nnx.Module`s with rngs in the state, we need to use `nnx.split_rngs` to properly vectorize over rngs state across parallel operations. For Conway's Game of Life specifically, the system doesn't use randomness during execution, so we could use `nnx.vmap` directly. However, we'll demonstrate the more general approach with `nnx.split_rngs` below, which works for any systems that maintain rngs state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_simulations = 8\n",
    "\n",
    "# Sample initial states\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, num_simulations)\n",
    "state_init = jax.vmap(sample_state)(keys)\n",
    "\n",
    "# Run independent simulations in parallel\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, nnx.Intermediate: 0, ...: None})\n",
    "state_final = nnx.split_rngs(splits=num_simulations)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda cs, state_init: cs(state_init, num_steps=num_steps, sow=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(cs, state_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]\n",
    "states.shape  # (num_simulations, num_steps, *spatial_dims, num_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.concatenate([state_init[:, None], states], axis=1)\n",
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_videos(frames, width=128, height=128, codec=\"gif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create your own complex system from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will build a **custom** complex system from scratch.\n",
    "\n",
    "In CAX, every complex system must inherit from the `ComplexSystem` class and implement two required methods:\n",
    "- `_step`: Defines how the system evolves over one time step\n",
    "- `render`: Converts the system state into a visual representation\n",
    "\n",
    "The `_step` method can perform any computation, but it must follow this signature: take a `State` as input, an optional `Input`, and return an updated `State`. Many complex systems (like cellular automata or particle systems) follow a common pattern where individual components (e.g., cells, particles, etc.) first perceive their local neighborhood, then update their state based on this perception and current state. For this reason, we recommend structuring the `_step` method into two phases:\n",
    "1. **Perceive**: Gather information from the neighborhood\n",
    "2. **Update**: Modify the state based on current state and perception\n",
    "\n",
    "This structure is optional but helps organize the code clearly.\n",
    "\n",
    "In the following example, we'll build a two-dimensional Neural Cellular Automaton (NCA) using CAX's pre-built Perceive and Update modules. Our NCA will feature:\n",
    "- Convolutional perception to gather neighborhood information\n",
    "- Residual update mechanisms for stable learning\n",
    "\n",
    "Note that we won't be training this neural cellular automaton in the current notebook - we'll focus solely on its construction and architecture.\n",
    "\n",
    "Since each NCA is unique, CAX does not offer pre-built, ready-to-use NCAs. However, it provides a versatile toolkit that empowers users to swiftly develop a custom cellular automaton suited to their specific experimental needs. In this section, we will explore how to efficiently create a neural cellular automaton using these tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_steps = 256\n",
    "num_spatial_dims = 2\n",
    "channel_size = 16\n",
    "\n",
    "num_kernels = 3\n",
    "hidden_size = 128\n",
    "cell_dropout_rate = 0.5\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Neural Cellular Automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final step to create the cellular automata is to combine the perceive and update modules.\n",
    "\n",
    "Optionally, we can create a custom CA class inheriting from the base CA class to implement a custom render method and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cax.core import ComplexSystem\n",
    "from cax.core.perceive import ConvPerceive\n",
    "from cax.core.update import ResidualUpdate\n",
    "from cax.utils import clip_and_uint8, rgba_to_rgb\n",
    "\n",
    "\n",
    "class CustomNCA(ComplexSystem):\n",
    "\t\"\"\"Custom neural cellular automaton.\"\"\"\n",
    "\n",
    "\tdef __init__(self, *, rngs: nnx.Rngs):\n",
    "\t\t\"\"\"Initialize custom cellular automaton.\n",
    "\n",
    "\t\tArgs:\n",
    "\t\t\trngs: rngs key.\n",
    "\n",
    "\t\t\"\"\"\n",
    "\t\t# CAX provides a set of perceive modules.\n",
    "\t\t# In this notebook, we will use a simple convolution perceive module.\n",
    "\t\tself.perceive = ConvPerceive(\n",
    "\t\t\tchannel_size=channel_size,  # Number of channels per cell in the grid\n",
    "\t\t\tperception_size=2 * channel_size,  # Number of channels per cell in the perception\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\t\t# CAX provides a set of update modules.\n",
    "\t\t# In this notebook, we will use a residual MLP update module.\n",
    "\t\tself.update = ResidualUpdate(\n",
    "\t\t\tnum_spatial_dims=2,  # Number of spatial dimensions\n",
    "\t\t\tchannel_size=channel_size,  # Number of channels per cell in the grid\n",
    "\t\t\tperception_size=2 * channel_size,  # Number of channels per cell in the perception\n",
    "\t\t\thidden_layer_sizes=(hidden_size,),  # Sizes of hidden layers in the MLP\n",
    "\t\t\trngs=rngs,\n",
    "\t\t)\n",
    "\n",
    "\tdef _step(self, state: State, input: Input | None = None, *, sow: bool = False) -> State:\n",
    "\t\tperception = self.perceive(state)\n",
    "\t\tnext_state = self.update(state, perception, input)\n",
    "\n",
    "\t\tif sow:\n",
    "\t\t\tself.sow(nnx.Intermediate, \"state\", next_state)\n",
    "\n",
    "\t\treturn next_state\n",
    "\n",
    "\t@nnx.jit\n",
    "\tdef render(self, state):\n",
    "\t\t\"\"\"Render state to RGB.\"\"\"\n",
    "\t\trgba = state[..., -4:]\n",
    "\t\trgb = rgba_to_rgb(rgba)\n",
    "\n",
    "\t\t# Clip values to valid range and convert to uint8\n",
    "\t\treturn clip_and_uint8(rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = CustomNCA(rngs=rngs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "\n",
    "from cax.utils.emoji import get_emoji\n",
    "\n",
    "size = 40\n",
    "pad_width = 16\n",
    "\n",
    "emoji_pil = get_emoji(\"âœ¨\")\n",
    "emoji_pil = emoji_pil.resize((size, size), resample=PIL.Image.Resampling.LANCZOS)\n",
    "\n",
    "y = jnp.array(emoji_pil, dtype=jnp.float32) / 255.0\n",
    "y = jnp.pad(y, ((pad_width, pad_width), (pad_width, pad_width), (0, 0)))\n",
    "\n",
    "mediapy.show_image(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_state(y):\n",
    "\t\"\"\"Sample a state with the target image.\"\"\"\n",
    "\tstate_shape = y.shape[:2] + (channel_size,)\n",
    "\tstate = jnp.zeros(state_shape)\n",
    "\n",
    "\t# Set the target image in the RGB channels\n",
    "\treturn state.at[:, :, :4].set(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the cellular automata for 256 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_init = sample_state(y)\n",
    "state_final = cs(state_init, num_steps=num_steps, sow=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clip the states to display as a video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediates = nnx.pop(cs, nnx.Intermediate)\n",
    "states = intermediates.state.value[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = jnp.clip(jnp.concatenate([state_init[None], states]), min=0.0, max=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you know how to run cellular automata with CAX! Go through the other notebooks to understand how to run classic cellular automata such as Game of Life or Lenia, or train neural cellular automata such as growing neural cellular automata.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = nnx.vmap(\n",
    "\tlambda cs, state: cs.render(state),\n",
    "\tin_axes=(None, 0),\n",
    ")(cs, states)\n",
    "\n",
    "mediapy.show_video(frames, width=256, height=256, codec=\"gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
