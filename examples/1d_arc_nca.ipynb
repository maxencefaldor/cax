{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1D-ARC Neural Cellular Automata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need Python 3.10 or later, and a working JAX installation. For example, you can install JAX with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"jax[cuda12]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, install CAX from PyPi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -U \"cax[examples]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import mediapy\n",
    "import optax\n",
    "from cax.core.ca import CA\n",
    "from cax.core.perceive.conv_perceive import ConvPerceive\n",
    "from cax.core.perceive.kernels import grad_kernel, identity_kernel\n",
    "from cax.core.update.residual_update import ResidualUpdate\n",
    "from flax import nnx\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "\n",
    "num_spatial_dims = 1\n",
    "channel_size = 64\n",
    "num_kernels = 2\n",
    "hidden_layer_sizes = (256,)\n",
    "cell_dropout_rate = 0.0\n",
    "\n",
    "num_embeddings = 10  # 10 colors in total\n",
    "features = 3  # embed in rgb\n",
    "\n",
    "batch_size = 16\n",
    "num_steps = 64\n",
    "learning_rate = 1e-3\n",
    "\n",
    "ds_size = 96\n",
    "\n",
    "key = jax.random.key(seed)\n",
    "rngs = nnx.Rngs(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/khalil-research/1D-ARC.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_path = \"./1D-ARC/dataset\"\n",
    "\n",
    "\n",
    "def process(input, output):\n",
    "\tinput = jnp.squeeze(jnp.array(input, dtype=jnp.int32))\n",
    "\toutput = jnp.squeeze(jnp.array(output, dtype=jnp.int32))\n",
    "\n",
    "\tassert input.shape == output.shape\n",
    "\n",
    "\tpad_size = ds_size - input.size\n",
    "\tpad_left, pad_right = pad_size // 2, pad_size - pad_size // 2\n",
    "\n",
    "\tinput_padded = jnp.pad(input, (pad_left, pad_right))\n",
    "\toutput_padded = jnp.pad(output, (pad_left, pad_right))\n",
    "\n",
    "\treturn jnp.stack([input_padded, output_padded])\n",
    "\n",
    "\n",
    "ds = []\n",
    "tasks = []\n",
    "for task_index, task_name in enumerate(os.listdir(ds_path)):\n",
    "\ttask_path = os.path.join(ds_path, task_name)\n",
    "\tfor task_file in os.listdir(task_path):\n",
    "\t\twith open(os.path.join(task_path, task_file)) as f:\n",
    "\t\t\tdata = json.load(f)\n",
    "\t\t\tinput_output = jnp.array(\n",
    "\t\t\t\t[\n",
    "\t\t\t\t\tprocess(data[\"train\"][0][\"input\"], data[\"train\"][0][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][1][\"input\"], data[\"train\"][1][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"train\"][2][\"input\"], data[\"train\"][2][\"output\"]),\n",
    "\t\t\t\t\tprocess(data[\"test\"][0][\"input\"], data[\"test\"][0][\"output\"]),\n",
    "\t\t\t\t],\n",
    "\t\t\t\tdtype=jnp.int32,\n",
    "\t\t\t)\n",
    "\t\t\ttasks.append(task_name)\n",
    "\t\t\tds.append(input_output)\n",
    "ds = jnp.stack(ds)\n",
    "\n",
    "unique_tasks = list(set(tasks))\n",
    "task_to_index = {task: index for index, task in enumerate(unique_tasks)}\n",
    "tasks = jnp.array([task_to_index[task] for task in tasks], dtype=jnp.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(key)\n",
    "\n",
    "tasks = jax.random.permutation(subkey, tasks)\n",
    "ds = jax.random.permutation(subkey, ds)\n",
    "\n",
    "split = int(0.9 * ds.shape[0])\n",
    "\n",
    "train_ds = ds[:split]\n",
    "train_tasks = tasks[:split]\n",
    "\n",
    "test_ds = ds[split:]\n",
    "test_tasks = tasks[split:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_state_with_sample(ca, sample, key):\n",
    "\t# Sample input and target\n",
    "\t(\n",
    "\t\t(input_embed_1, output_embed_1),\n",
    "\t\t(input_embed_2, output_embed_2),\n",
    "\t\t(input_embed_3, output_embed_3),\n",
    "\t\t(input_embed, _),\n",
    "\t) = ca.embed_input(sample)\n",
    "\n",
    "\t# Create context\n",
    "\tcontext_1 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_2 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_3 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_4 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_5 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext_6 = jnp.concatenate(\n",
    "\t\t[\n",
    "\t\t\tinput_embed_3,\n",
    "\t\t\toutput_embed_3,\n",
    "\t\t\tinput_embed_2,\n",
    "\t\t\toutput_embed_2,\n",
    "\t\t\tinput_embed_1,\n",
    "\t\t\toutput_embed_1,\n",
    "\t\t],\n",
    "\t\taxis=-1,\n",
    "\t)\n",
    "\tcontext = jax.random.choice(\n",
    "\t\tkey, jnp.array([context_1, context_2, context_3, context_4, context_5, context_6])\n",
    "\t)\n",
    "\n",
    "\t# Initialize state\n",
    "\tstate = jnp.zeros((ds_size, channel_size))\n",
    "\tstate = state.at[..., :3].set(input_embed)\n",
    "\tstate = state.at[..., 3 : 18 + 3].set(context)\n",
    "\treturn state, sample[-1, -1]\n",
    "\n",
    "\n",
    "def init_state(ca, key):\n",
    "\tkey_sample, key_flip, key_perm, key_init = jax.random.split(key, 4)\n",
    "\n",
    "\t# Sample dataset\n",
    "\ttask_index = jax.random.choice(key_sample, train_tasks)\n",
    "\tsample = jax.random.choice(key_sample, train_ds)\n",
    "\n",
    "\t# Flip sample half of the time\n",
    "\tflip = jax.random.bernoulli(key_flip, p=0.5)\n",
    "\tsample = jnp.where(flip < 0.5, sample, jnp.flip(sample, axis=-1))\n",
    "\n",
    "\t# Permute colors\n",
    "\tcolor_perm = jnp.concatenate(\n",
    "\t\t[jnp.array([0], dtype=jnp.int32), jax.random.permutation(key_perm, jnp.arange(9)) + 1]\n",
    "\t)\n",
    "\tsample = color_perm[sample]\n",
    "\n",
    "\treturn init_state_with_sample(ca, sample, key_init)\n",
    "\n",
    "\n",
    "def init_state_test(ca, key):\n",
    "\tkey_sample, key_init = jax.random.split(key)\n",
    "\n",
    "\t# Sample dataset\n",
    "\ttask_index = jax.random.choice(key_sample, test_tasks)\n",
    "\tsample = jax.random.choice(key_sample, test_ds)\n",
    "\n",
    "\treturn init_state_with_sample(ca, sample, key_init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceive = ConvPerceive(\n",
    "\tchannel_size=channel_size,\n",
    "\tperception_size=num_kernels * channel_size,\n",
    "\trngs=rngs,\n",
    "\tkernel_size=(3,),\n",
    "\tfeature_group_count=channel_size,\n",
    ")\n",
    "update = ResidualUpdate(\n",
    "\tnum_spatial_dims=num_spatial_dims,\n",
    "\tchannel_size=channel_size,\n",
    "\tperception_size=num_kernels * channel_size,\n",
    "\thidden_layer_sizes=hidden_layer_sizes,\n",
    "\trngs=rngs,\n",
    "\tcell_dropout_rate=cell_dropout_rate,\n",
    ")\n",
    "embed_input = nnx.Embed(num_embeddings=num_embeddings, features=features, rngs=rngs)\n",
    "\n",
    "\n",
    "class ARCNCA(CA):\n",
    "\tembed_input: nnx.Embed\n",
    "\n",
    "\tdef __init__(self, perceive, update, embed_input):\n",
    "\t\tsuper().__init__(perceive, update)\n",
    "\t\tself.embed_input = embed_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = jnp.concatenate(\n",
    "\t[identity_kernel(ndim=num_spatial_dims), grad_kernel(ndim=num_spatial_dims)], axis=-1\n",
    ")\n",
    "kernel = jnp.expand_dims(jnp.concatenate([kernel] * channel_size, axis=-1), axis=-2)\n",
    "perceive.conv.kernel = nnx.Param(kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca = ARCNCA(perceive, update, embed_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of params: 49886\n"
     ]
    }
   ],
   "source": [
    "params = nnx.state(ca, nnx.Param)\n",
    "print(\"Number of params:\", jax.tree.reduce(lambda x, y: x + y.size, params, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_steps = 100000\n",
    "lr_sched = optax.linear_schedule(\n",
    "\tinit_value=learning_rate, end_value=0.1 * learning_rate, transition_steps=num_train_steps // 10\n",
    ")\n",
    "\n",
    "optimizer = optax.chain(\n",
    "\toptax.clip_by_global_norm(1.0),\n",
    "\toptax.adam(learning_rate=lr_sched),\n",
    ")\n",
    "\n",
    "params = nnx.All(\n",
    "\tnnx.Param,\n",
    "\t# nnx.Not(nnx.PathContains(\"perceive\"))\n",
    ")\n",
    "optimizer = nnx.Optimizer(ca, optimizer, wrt=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ce(state, output):\n",
    "\treturn jnp.mean(optax.softmax_cross_entropy_with_integer_labels(state[..., -10:], output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def loss_fn(ca, key):\n",
    "\tkeys = jax.random.split(key, batch_size)\n",
    "\tstate, output = jax.vmap(init_state, in_axes=(None, 0))(ca, keys)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=batch_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda ca, state: ca(state, num_steps=num_steps),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(ca, state)\n",
    "\n",
    "\tloss = ce(state, output)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nnx.jit\n",
    "def train_step(ca, optimizer, key):\n",
    "\tloss, grad = nnx.value_and_grad(loss_fn, argnums=nnx.DiffState(0, params))(ca, key)\n",
    "\toptimizer.update(grad)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(ca, eval_ds):\n",
    "\teval_size = eval_ds.shape[0]\n",
    "\tstate, output = jax.vmap(init_state_with_sample, in_axes=(None, 0, None))(ca, eval_ds, key)\n",
    "\n",
    "\tstate_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "\tstate = nnx.split_rngs(splits=eval_size)(\n",
    "\t\tnnx.vmap(\n",
    "\t\t\tlambda ca, state: ca(state, num_steps=num_steps, all_steps=True),\n",
    "\t\t\tin_axes=(state_axes, 0),\n",
    "\t\t)\n",
    "\t)(ca, state)\n",
    "\n",
    "\t# Convert logits to symbols\n",
    "\tfinal_state_logits = state[:, -1, :, -10:]\n",
    "\tfinal_state = jnp.argmax(final_state_logits, axis=-1)\n",
    "\n",
    "\t# Successful if all symbols match in the prediction\n",
    "\treturn jnp.sum(jnp.all(final_state == output, axis=-1)) / eval_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_interval = 128\n",
    "\n",
    "pbar = tqdm(range(num_train_steps), desc=\"Training\", unit=\"train_step\")\n",
    "losses = []\n",
    "for i in pbar:\n",
    "\tkey, subkey = jax.random.split(key)\n",
    "\tloss = train_step(ca, optimizer, subkey)\n",
    "\tlosses.append(loss)\n",
    "\n",
    "\tif i % print_interval == 0 or i == num_train_steps - 1:\n",
    "\t\tavg_loss = sum(losses[-print_interval:]) / len(losses[-print_interval:])\n",
    "\t\ttest_acc = accuracy(ca, test_ds)\n",
    "\t\ttrain_acc = accuracy(ca, train_ds)\n",
    "\t\tpbar.set_postfix(\n",
    "\t\t\t{\n",
    "\t\t\t\t\"Average Loss\": f\"{avg_loss:.3e}\",\n",
    "\t\t\t\t\"Test Accuracy\": f\"{test_acc:.2%}\",\n",
    "\t\t\t\t\"Train Accuracy\": f\"{train_acc:.2%}\",\n",
    "\t\t\t}\n",
    "\t\t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = 8\n",
    "\n",
    "key, subkey = jax.random.split(key)\n",
    "keys = jax.random.split(subkey, n_examples)\n",
    "state, output = jax.vmap(init_state_test, in_axes=(None, 0))(ca, keys)\n",
    "\n",
    "state_axes = nnx.StateAxes({nnx.RngState: 0, ...: None})\n",
    "state = nnx.split_rngs(splits=n_examples)(\n",
    "\tnnx.vmap(\n",
    "\t\tlambda ca, state: ca(state, num_steps=num_steps, all_steps=True),\n",
    "\t\tin_axes=(state_axes, 0),\n",
    "\t)\n",
    ")(ca, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = state[..., -10:]\n",
    "pred = jnp.argmax(logits, axis=-1)\n",
    "colors = [\"black\", \"red\", \"green\", \"blue\", \"yellow\", \"purple\", \"orange\", \"pink\", \"brown\", \"gray\"]\n",
    "color_map = {\n",
    "\t\"black\": [0, 0, 0],\n",
    "\t\"red\": [255, 0, 0],\n",
    "\t\"green\": [0, 255, 0],\n",
    "\t\"blue\": [0, 0, 255],\n",
    "\t\"yellow\": [255, 255, 0],\n",
    "\t\"purple\": [128, 0, 128],\n",
    "\t\"orange\": [255, 165, 0],\n",
    "\t\"pink\": [255, 192, 203],\n",
    "\t\"brown\": [165, 42, 42],\n",
    "\t\"gray\": [128, 128, 128],\n",
    "}\n",
    "\n",
    "# Create a lookup table for faster conversion\n",
    "color_lookup = jnp.array([color_map[color] for color in colors])\n",
    "\n",
    "# Convert pred to RGB\n",
    "state_rgb = color_lookup[pred]\n",
    "\n",
    "# Normalize RGB values to [0, 1] range\n",
    "state_rgb = state_rgb.astype(jnp.float32) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"show_images\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAAA+UlEQVR4nO3bQQ6CMBBA0cHjcEouwz3ce6i6I2KEr43MSPwvrpqQ1p+hroyo0OZosfpMMbW2Wnk0j+PL9cPPGTHk7rjae9/TydrG+tEuudv1W7okD9FpAlUpC9TzplxvXz8GcoJA2SUdn9/Ty1OZh66coL7vOeTe0z/9im2F+JcJOgUDAQOB4kCVP6LvcYKAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIFAcaDkP391cIKAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIHAHYr9HJiAz0EnAAAAAElFTkSuQmCC\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAAA+UlEQVR4nO3bQQ6CMBBA0cHjcEouwz3ce6i6I2KEr43MSPwvrpqQ1p+hroyo0OZosfpMMbW2Wnk0j+PL9cPPGTHk7rjae9/TydrG+tEuudv1W7okD9FpAlUpC9TzplxvXz8GcoJA2SUdn9/Ty1OZh66coL7vOeTe0z/9im2F+JcJOgUDAQOB4kCVP6LvcYKAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIFAcaDkP391cIKAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIHAHYr9HJiAz0EnAAAAAElFTkSuQmCC\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAAAmElEQVR4nO3YIQ4DMQwAwaj//3NKCyotO/ukGeQwa0GAz3nQPef+fyw1sOD9HdYHGnDfFuUzvcB2AgEAAADAoLddXF0Ui0BBoLA90PiftT3QOIGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKAgUBAoCBYGCQEGgIFAQKHwBQKcMTaE28sAAAAAASUVORK5CYII=\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAABSUlEQVR4nO3XMWrDMBhA4d+lp3Hnzr2HPXTvgbJniM/Rzp3j67iDaQkJzTNE/m3B+yZDIFIekiI3sb4pYmjbUt/WjeP8MLRt//u8kimiWXWAS6dCjbqLKAmzf1p/iLpVE6g7HDcZ93mTUZe4LdIdjsPHe0Q0EVPWNFJX0J1VcPXR/fWSVifyt9iDOyV/o22wxW5/5LxxIqI/j6eXYheCInZxBs3J+vMY2x3G/6nmX+xPwTvnEvUFSl5i9QVKtq9A09f31lO4tq9ACzWJF6G8l9Xps9jqaN5epybCl9U9qDJQ5lFVZaBMBgLVBip35N9XbaAsBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgYCBgI/o5c0zWn17TQAAAAASUVORK5CYII=\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAABFUlEQVR4nO3YMW6DQBBG4SHHcZ8+R9vL5B52zaEmBbFjI0uvnD/Se6KAitGnXQRUZfR9uaxa3bVqddXjmG18gL/6uldVdz3rJMy3TQ9wrvs81OyIH6N3/welA42v8Dig7SC57sfl+GMoC2it9TgfXztHWUCnEowige77K6FIoNdmH0PpQOO7LBXo63N6gt9SgZ7yTfp9429AR7lAIYUCbSHrJxYop1Cgvu0hiygUKCeBIIGgXKC+RXyy5gKFJBAkECQQFA3UAb8Wo4ESEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBII+gFHtCegkBFnNwAAAABJRU5ErkJggg==\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAABDklEQVR4nO3XQWrDMBgF4aceR0dqDlP1MD5Scx11YRxCcTJ0EUmBmYUx5hfGH0Lg5MVttW61Jr2l7U960pOW1o/7fWar9X7V7Tqxnny8+h2X63W/afl6Pvl5TK5TGQCU5PLz8MvLbeZMZwWyEUB/KjyyUOOA+mOZffusCTcOqKT/f8n8hgCVZzSnCqdH0pQmnEHvlUCQQJBA0Byg7+O3Y/3cQdBMoLfYR+4gSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCBIIEggSCDoFxCEJHxVzNXoAAAAAElFTkSuQmCC\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAABFElEQVR4nO3Zyw3CMBQFUUM5VGmKoQ/2FAULPoogMBELvxtljtgRyWbkRxRobazrz3dPh8P9ms9XiWtru8AlZ3OM3ujTfvB6VZ/zb6MDLTEbsWrKEgPN2sqILZQziaGB2kcjRyxUdKCEQxQdKEF8oPOldv2c28VX08lawXarVD2RxY+Yltv0Ceq9V29hXkqgJUq+odcUqISBgIGAgYCBgIGAgYCBgIGAgYCBgIGAgUBuoKo/wt6EBgqp02ID5QgNdGy9egsPoYFy5AYKOUSJgXpGmrvEQC8JpaIDJTAQMBAwEDAQMBAwEDAQMBAwEDAQMBAwEDAQMBAwEDAQMBAwEIgLlPA79FRcoDQGAgYCBgIGAgYCN0BQHXVmTRo5AAAAAElFTkSuQmCC\"/></td><td style=\"padding:1px;\"><img width=\"128\" height=\"128\" style=\"image-rendering:pixelated; object-fit:cover;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAGAAAABACAIAAABqVuVZAAABlElEQVR4nO3ZMXLCMBSE4VWOo9yHAh8lRZ6KHMW+EWo4zEshEG5gmYAlObNf5RmJCP0jE8YEbG+OEcDxlLFg+YnroSlnB5YYj1+5DJVpAMJ0eWFVh8rMKeet37lvvUBdZo7RHbheuGOOsezfAXf4fButypw5RsB9Rh0qf+H/KPu5BcLluuzRAYOVmWa23nlNecnYI9BHm2VSsnodrie3XAS44fvBa6d82vKtEY0CrRlSCnZvdJ3ylTnv0iLQn/eTkoXQ+cOm9Ql65X7pEqvDLbYvCkQoEKFARJd/84++9YxGJ4hQIKJdoOUz8knjaRfofDg0W+uNdIsRCkQoEKFAhAIRCkQoEKFAhAIRewpkltov2ifQ+olHl20/b+gTZHb3yVGzX36GCDTyIRoi0DN6RdxNoF4UiFAgQoEIBSIUiOgZaOSvP5VOEKFAhAIRCkQoEKFAhAIRCkQoEKFAxHCBHjyH7mK4QKNRIEKBiE4/HO7hQUehE0QoEKFAxD4CdfzM2kegjhSIUCBCgQgFIhSIUCBCgYhfChx58o+6aG8AAAAASUVORK5CYII=\"/></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mediapy.show_images(state_rgb, width=128, height=128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
